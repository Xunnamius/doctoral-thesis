\chapter{Background and Related Work} \label{chp:related}

Some of the most popular cryptosystems offering a confidentiality guarantee for
data at rest employ a symmetric encryption scheme known as a Tweakable
Enciphering Scheme (TES)~\cite{STES,XEX}. There have been numerous TES-based
constructions securing data at rest~\cite{STES,CMC,HCTR}, including the well
known XEX-based XTS operating mode of AES~\cite{XTS} explored earlier in this
work. Almost all TES constructions and the storage management systems that
implement them use one or more block ciphers as their primary
primitive~\cite{TES-From-Stream-Cipher,STES}.

Our StrongBox implementation borrows from the design of these systems. One in
particular is \emph{dm-crypt}, a Linux framework employing a
\textit{LinuxDeviceMapper} to provide a virtual block interface for physical
block devices. Dm-crypt provides an implementation of the AES-XTS algorithm
among others and is used widely in the Linux ecosystem~\cite{DmC-Android,
dmcrypt}. The algorithms provided by dm-crypt all employ block
ciphers~\cite{dmcrypt}. Instead of a block cipher, however, StrongBox uses a
stream cipher to provide the same confidentiality guarantee and consistent or
better I/O performance. Further unlike dm-crypt and other similar virtualization
frameworks, StrongBox's ciphering operations do not require sector level tweaks,
depending on the implementation. With StrongBox, several physical blocks
consisting of one or more sectors are considered as discrete logical units, \ie
nuggets and flakes.

Substituting a block cipher for a stream cipher forms the core of several
contributions to the state-of-the-art~\cite{STES, TES-From-Stream-Cipher}.
Chakraborty et al. proposed STES---a stream cipher based low cost scheme for
securing stored data~\cite{STES}. STES is a novel TES which can be implemented
compactly with low overall power consumption. It combines a stream cipher and a
universal hash function via XOR and is targeting low cost FPGAs to provide
confidentiality of data on USBs and SD cards. Our StrongBox, on the other hand,
is not a TES and does not directly implement a TES. StrongBox combines a stream
cipher with nonce ``tweak'' and nugget data via XOR and is targeting any
configuration employing a well-behaved Log-structured Filesystem (LFS) at some
level to provide confidentiality of data.

Offering a transparent cryptographic layer at the block device level has been
proposed numerous times~\cite{SBD}. Production implementations include storage
management systems like dm-crypt. Specifically, Hein et al. proposed the Secure
Block Device (SBD)~\cite{SBD}---an ARM TrustZone secure world transparent
filesystem encryption layer optimized for ANDIX OS and implemented and evaluated
using the Linux Network Block Device (NBD) driver. StrongBox is also implemented
and evaluated using the NBD, but is not limited to one specific operating
system. Further unlike StrongBox, SBD is not explicitly designed for use outside
of the ARM TrustZone secure world. Contrarily, StrongBox was designed to be used
on any system that provides a subset of functionality provided by a Trusted
Platform Module (TPM) and/or Trusted Execution Environment (TEE). Specifically,
StrongBox requires the availability of a dedicated hardware protected secure
monotonic counter to prevent rollback attacks and ensure the freshness of
StrongBox. The primary design goal of StrongBox is to achieve provide higher
performance than the industry standard AES-XTS algorithm utilizing a stream
cipher.

StrongBox's design is only possible because of the availability of hardware
support for security, which has been a major thrust of research efforts
~\cite{asplos1,asplos2,asplos3,asplos4,isca1,isca2}, and is now available in
almost all commercial mobile processors ~\cite{TPM,TEE,RPMB,Kirovski}. Our
implementation makes use of the replay protected memory block on eMMC devices
~\cite{eMMC-standard,RPMB}, but it could be reimplemented using any hardware
that supports persistent, monotonic counters.

The combination of trusted hardware and monotonic counters enables new security
mechanisms. For example, van Dijk et al. use this combination allow clients to
securly store data on an untrusted server ~\cite{CSAIL-TPM}. Like StrongBox,
their approach relies on trusted hardware (TPM specifically \cite{TPM}), logs,
and monotonic counters. The van Dijk et al. approach, however, uses existing
secure storage and is not concerned with storage speed. StrongBox uses these
same mechanisms along with novel metadata layout and system design to solve a
different problem: providing higher performance than AES-XTS based approaches.

Achieving on-drive data integrity protection through the use of checksums has
been used by filesystems and many other storage management systems. Examples
include ZFS~\cite{ZFS} and others~\cite{SBD}. As we explore later with HASCHK,
checksums also form the backbone of authenticity protections for objects
downloaded over the internet. For our implementation of StrongBox, we used the
Merkle Tree library offered by SBD to manage our in-memory checksum
verification. A proper implementation of StrongBox need not use the SDB SHA-256
Merkle Tree library. It was chosen for convenience.

Further, trading off security for energy, performance, and other concerns is not
a new research area~\cite{ScalableSecurity, WolterReinecke, ZengChow1,
HaleemEtAl, LiOmiecinski, Merkel4, Merkle3}. Goodman et al. introduced
selectively decreasing the security of some data to save
energy~\cite{ScalableSecurity}. However, their approach is designed for
communication and only considered iteration/round count, thus it did not
anticipate the need for SwitchCrypt's generic interface, switching strategies,
or quantification framework. Wolter and Reinecke study approaches to quantifying
security in several contexts~\cite{WolterReinecke}. This study anticipates the
value of dynamically switching ciphers but proposes no mechanisms to enable this
in FDE. Similarly, companies like LastPass and Google have explored
performance-security tradeoffs. Google's Adiantum uses a reduced-round version
of ChaCha in exchange for performance~\cite{Adiantum}. While not an FDE
solution, LastPass has dealt with scaling the number of iterations of PBKDF\#2,
trading performance for security during login sessions~\cite{LastPass}.

Finally, we examine prior approaches to guaranteeing resource integrity
over the internet. We then highlight some drawbacks to these approaches and how
HASCHK differs. \\

\noindent\textbf{Anti-malware software, heuristics, and blacklists.}
Anti-malware software is a heuristic-based program designed for the specific
purpose of detecting and removing various kinds of malware. However, updates to
anti-malware definitions often lag behind or occur in response to the release of
crippling malware. For example, during the 2017 compromise of the HandBrake
distribution mirror, users who first ran the compromised HandBrake image through
\textit{VirusTotal}---a web service that will run a resource through several
dozen popular anti-malware products---received a report claiming no infections
were detected despite the presence of the Proton malware~\cite{SCA-HB1}. In the
2012 compromise of SourceForge's CDN, the malicious changes to the phpmyAdmin
image do not appear as malware to anti-malware software~\cite{SCA-PMA1}.

Similarly, all modern browsers employ heuristic and blacklist-based detection
and prevention schemes in an attempt to protect users from malicious content on
the internet. The warnings generated by browser-based heuristics and blacklists
are also reactive rather than proactive; hence, they are generally ineffective
at detecting active or novel attacks on the integrity of the resources
downloaded over the internet.

On the other hand, HASCHK relies on no heuristics or blacklists and is not
anti-malware software. HASCHK is a protocol for automating checksum
verification of resources. This ensures download integrity---that a user is
receiving the expected resource a provider is advertising---not that the
expected resource is not malware. \\

\noindent\textbf{Link Fingerprints and Subresource Integrity.} The Link
Fingerprints (LF) draft describes an early HTML hyperlinks and URI based
resource integrity verification scheme that ``provides a backward-compatible
technique for resource providers to ensure that the resource originally
referenced is the same as the resource retrieved by an end user.''~\cite{LF}.
The World Wide Web Consortium's (W3C) Subresource Integrity (SRI) describes a
similar HTML-based scheme designed exclusively with CDNs and web assets in mind.

Like HASCHK, both LF and SRI employ cryptographic digests to ensure no
changes of any kind have been made to a resource~\cite{SRI}. Unlike HASCHK,
LF and SRI apply \emph{only to resources referenced by script and link HTML
elements}; HASCHK, on the other hand, can ensure the integrity of \emph{any
arbitrary resource downloaded over the internet}, even outside of HTML web pages
and browser software. Further, the checksums contained in the HTML source must
be accurate for SRI to work. If the system \emph{behind} the CDN is compromised,
the attacker can alter the HTML and inject a malicious checksum or even strip
checksums from the HTML entirely. With HASCHK, however, an attacker would
additionally have to compromise the separate backend system that advertises the
provider's resources, thus raising the bar. \\

\noindent\textbf{Content-MD5 Header.} The Content-MD5 header field is a
deprecated email and HTTP header that delivers a checksum similar to those used
by Subresource Integrity. It was removed from the HTTP/1.1 specification because
of the inconsistent implementation of partial response handling between
vendors~\cite{HTTP1.1}. Further, the header could be easily stripped off or
modified by proxies and other intermediaries~\cite{MD5Header}. HASCHK
exhibits none of these weaknesses. \\

\noindent\textbf{Deterministic Build Systems and Binary Transparency.} A
deterministic build system is one that, when given the same source, will
deterministically output the same binary on every run. For example, many
packages in Debian~\cite{ReproBuildsDebian} and Arch Linux can be rebuilt from
source to yield an identical byte for byte result~\cite{ReproBuilds}, allowing
for verification of the \emph{Integration} and perhaps \emph{Development} supply
chain phases (see \tblref{attacks}). Further, using a merkle
tree~\cite{MerkleTree} or similar construction, an additional chain of trust can
be established that allows for public verification of the \emph{Deployment},
\emph{Maintenance}, and \emph{Retirement} supply chain phases. Companies such as
Mozilla refer to the latter as ``Binary Transparency.''

Like HASCHK, binary transparency establishes a public verification scheme
that allows third party consumers access to a listing of source updates
advertised by a provider~\cite{BinaryTransparency}. Consumers can leverage
deterministic build systems and Binary Transparency together to ensure their
software is the same software deployed to every other system. Unlike HASCHK,
binary transparency only allows a user to verify the integrity of \emph{source
updates to binaries}; our protocol allows a user to verify the integrity of
\emph{any arbitrary resource} while specifically addressing co-hosting. \\

\noindent\textbf{Stickler and Cherubini et al.} Stickler~\cite{Stickler} by Levy
et al. is an automated JavaScript-based stand-in for SRI for protecting the
integrity of web application files hosted on CDNs. Stickler does not require any
modifications to the client (\ie{ a frontend}), instead delivering a bootloader
to load and verify resources signed before the fact. However, as it was designed
to stand-in for SRI, Stickler inherits some of SRI's limitations. Specifically:
Stickler was not designed to protect arbitrary resource downloads and, if the
publisher's server is compromised, Stickler's bootloader can be stripped out of
the initial HTTP response altogether. Something like this is not possible with
HASCHK.

The automated checksum verification approach described by Cherubini et
al.~\cite{Cherubini}, also based on SRI, is similarly vulnerable to (and relies
upon) co-hosting. Cherubini's browser extension works by both looking for
embedded checksums in download links (SRI) and extracting hexadecimal strings
that look like checksums directly from the HTML source. An attacker, after
compromising the resource file, need only modify the provider's HTML file to
inject a corrupted ``integrity'' attribute containing a checksum matching that
corrupted resource, causing Cherubini's extension to misreport the dangerous
download as safe~\cite{Cherubini}. Additionally, Cherubini's extension: (1) does
not alert users when corresponding authoritative checksums are not found, which
means an attacker can simply strip all checksums from the server response to
pass off compromised resources to users; (2) considers a download ``safe'' so
long as \emph{any checksum found on the page matches it}, which means an
attacker can just inject the compromised checksum somewhere in the HTML source
alongside the legitimate checksum to similarly pass off compromised resources to
users; (3) does not support direct downloads, \ie{ when a user enters a
resource's URI into the browser manually rather than click a hyperlink}. None of
this is a problem for HASCHK.
