\section{Motivation} \label{sec:hc-motivation}

Downloading resources over the internet comes with many risks, including the
chance that the resource has been corrupted, or that an attacker has replaced
your desired resource with a compromised version. The de facto standard for
addressing this risk is the use of \emph{checksums} coupled with a secure
transport layer; users download a resource, compute its checksum, and compare
that with an authoritative checksum. Problems with this approach include (1)
\emph{user apathy}---for most users, calculating and verifying the checksum is
too tedious; and (2) \emph{co-hosting}---an attacker who compromises a resource
can trivially compromise a checksum hosted on the same system. The co-hosting
problem remains despite advancements in tools that automate checksum
verification and generation. In this paper we propose \emph{HASCHK}, a resource
verification protocol expanding on de facto checksum-based integrity protections
to defeat co-hosting while automating the tedious parts of checksum
verification. We evaluate HASCHK's security, practicality, and ease of
deployment by implementing a proof-of-concept Google Chrome extension. Our
implementation is tested versus common resource integrity violations. We find
our approach is more effective than existing mitigation methods, significantly
raises the bar for the attacker, and is deployable at scale.

In 2010, through compromising legitimate applications available on trusted
vendor websites, nation-state actors launched the Havex malware, targeting
aviation, defense, pharmaceutical, and other companies in Europe and the United
States~\cite{SCA-HAVEX1, SCA-HAVEX2}. In 2012, attackers compromised an official
phpMyAdmin download mirror hosted by reputable software provider SourceForge.
The backdoored version of the popular database frontend was downloaded by
hundreds of users, potentially allowing attackers to gain access to private
customer data~\cite{SCA-PMA1, SCA-PMA2}. In 2016, attackers broke into the Linux
Mint distribution server and replaced a legitimate Mint ISO with one containing
a backdoor, infecting hundreds of machines with the malware~\cite{SCA-MINT1,
SCA-MINT2}. Over a four day period in 2017, users of the popular HandBrake open
source video transcoder on Mac/OSX were made aware that, along with their
expected video software, they may have also downloaded a trojan that was
uploading their sensitive data to a remote server~\cite{SCA-HB1}. HandBrake
developers recommended users perform \emph{checksum verification} to determine
if their install was compromised~\cite{SCA-HB2}.

Clearly, downloading resources over the internet (TCP/IP) comes with
considerable risk. This risk can be divided into three broad concerns: response
authentication, communication confidentiality, and resource integrity. Response
authentication allows us to determine if a response received indeed originates
from its purported source through, for instance, the adoption of a Public Key
Infrastructure (PKI) scheme~\cite{PKI}. Communication confidentiality allows us
to keep the data transacted between two or more parties private through some
form of encryption, such as AES~\cite{AES}. Finally, resource integrity allows
us to verify that the data we are receiving is the data we are expecting to
receive.

When it comes to response authentication and communication confidentiality
concerns on the internet, the state-of-the-art in attack mitigation is Transport
Layer Security (TLS) and its Hyper Text Transfer Protocol (HTTP)/PKI based
implementation, HTTPS~\cite{TLS1.2, TLS1, TLS0, HTTPS, PKI}. Assuming well
behaved certificate authorities and modern browsing software, TLS and related
protocols, when properly deployed, mitigate myriad attacks on authentication and
confidentiality.

However, as a \textit{communication} protocol, TLS only guarantees the integrity
of each \textit{end-to-end communication} via message authentication code
(MAC)~\cite{TLS1.2}. But protected encrypted communications mean nothing if the
contents of those communications are corrupted before the fact. Hence, attacks
against the integrity of resources at the application layer (rather than the
transport layer) are outside the threat model addressed by TLS and
HTTPS~\cite{TLS1.2, HTTPS}.

Attacks on resource integrity can be considered a subset of \emph{Supply Chain
Attacks} (SCA). Rather than attack an entity directly, SCAs are the compromise
of an entity's software source code (or any product) via cyber attack, insider
threat, upstream asset compromise, trusted hardware/vendor compromise, or other
attack on one or more phases of the software development life
cycle~\cite{NIST-SCA}. These attacks are hard to detect, even harder to prevent,
and have the goal of infecting and exploiting targets and victims by abusing the
trust between consumer and reputable software vendor~\cite{SCA}.

Ensuring the integrity of resources exchanged over the internet despite SCAs and
other active attacks is a hard and well studied problem~\cite{MD5Header,
HTTP1.1, HTTPS, SRI, LF, OpenPGP1, DNSSEC, PKI, Cherubini, Stickler}. The de
facto standard for addressing this risk in the generic case is using
\textit{checksums} coupled with some secure transport medium like TLS/HTTPS.
Checksums in this context are cryptographic digests generated by a cryptographic
hashing function~\cite{Rogaway} run over the resource's file contents. When a
user downloads a file from some source, they are expected to run the same
cryptographic hashing function over their version of the resource to yield a
local checksum and then match it with a checksum given to them by some trusted
authority.

However, checksums come up short as a solution to the resource integrity
problem. Foremost is a well-understood but harsh reality: \textbf{user apathy}.
Most users will not be inconvenienced with manually calculating checksums for
the resources they download~\cite{Cherubini, Fagan}; moreover, most users will
not take the time to understand how checksums and integrity verification
work~\cite{Cherubini, Tan, Hsiao}. While detailing how they gained unauthorized
access to the servers, one of the hackers behind the 2016 breach of Linux Mint's
distribution system went so far as to comment (in respect to checksums): ``Who
the [expletive] checks those anyway?''~\cite{SCA-MINT3}. Hardly unique to
checksums, designers of security schemes from HTTPS to PGP to Google Chrome
dangerous download warnings have found user apathy a difficult problem space to
navigate~\cite{PGPBad, Cherubini, Akhawe, ChromeClickThrough, Egelman1,
Egelman2, Modic, Reeder, Silic, Bianchi}.

Even if a user feels the urge to manually calculate and verify a resource's
checksum, they must search for a corresponding ``authoritative checksum'' to
compare against. As there is no standard storage or retrieval methods for
checksums, they could be stored anywhere, or even in multiple different
locations that must then be kept consistent~\cite{Cherubini}; users are not
guaranteed to find an authoritative checksum, even if they are published online
somewhere, even if they appear on the same page as the resource they are trying
to protect. If users do manage to find the authoritative checksum manually and
also recognize the checksums are different, the user is then expected to ``do
the right thing,'' whatever that happens to be in context.

A major contributor to this confusion is the tradeoff made by
\textbf{co-hosting} a resource and its authoritative checksum on the same
distribution system, \eg{ a web page hosting both a hyperlink pointing to a
resource and that resource's authoritative checksum together}. While
cost-effective for the provider and less confusing for the user, an attacker
that compromises a system hosting both a resource and its checksum together can
mutate both, rendering the checksum irrelevant~\cite{Stickler}. This is true for
automated checksum verification solutions as well~\cite{Cherubini}. The
co-hosting problem was demonstrated by the 2016 hack of Linux Mint's
distribution server~\cite{SCA-MINT1, SCA-MINT2}.

For these reasons, checksums as they are typically deployed are not very
effective at guaranteeing resource integrity, even if automatic verification by
web clients is attempted. Recognizing this, some corporations and large entities
rely instead on approaches like digital signature verification, code signing,
and Binary Transparency~\cite{PKI, BinaryTransparency}. These roll-your-own
solutions, often proprietary, have been deployed successfully to mitigate
resource integrity attacks in mature software package ecosystems like Debian/apt
and Red Hat/yum and walled-garden app stores like Google Play, Apple App Store,
and the Microsoft Store.

Unfortunately, not all resources available on the internet are acquired through
mature software package ecosystems with built-in PKI support. In the United
States for instance, most internet users download software directly from
websites or other locations~\cite{Cherubini, Ryan}. 
%Nor are all resources downloaded over the internet software binaries. 
Moreover, such schemes are not compatible with one another and cannot scale to
secure arbitrary resources on the internet without significant cost and
implementation/deployment effort.

This paper addresses these problems by proposing HASCHK, a novel protocol for
verifying the integrity of arbitrary resources downloaded over the internet that
is a complete replacement for typical checksum-based schemes, significantly
raises the bar for the attacker, and can be implemented in more than just
browser software. To overcome the challenges posed by user apathy and
co-hosting, HASCHK is implemented in two parts: a backend for resource
\emph{providers} and a frontend for resource \emph{consumers}---\ie{ (end)
users}. Providers use a high availability backend to advertise which resources
they provide for download. To defeat co-hosting, this backend exists separately
from the system offering those resources. To account for user apathy, the
frontend client automatically computes a (non-authoritative) checksum
identifying the resource, queries the backend using that checksum, and mitigates
the threat to the user in the case where the download is deemed compromised.
Hence, HASCHK consists of both the protocol by which these pieces communicate
and their implementation.

We approach these problems with four key concerns in mind. (1) HASCHK
frontends must provide security guarantees transparently without adding any
extra user burden in the common case. Here, an optimal implementation avoids
relying on the user to overcome apathy in the interest of security while
accounting for the tendency of some users to click through security warnings so
as to not be inconvenienced. The former is achieved through automation and the
latter through careful design. (2) HASCHK must be low effort for providers to
integrate and deploy in concert with the resource(s) they are meant to protect.
There must be no requirement to configure a secondary system solely dedicated to
hosting checksums. (3) The protocol is not tightly coupled with any particular
high availability system. (4) Neither application, website source code changes,
user-facing server, nor web infrastructure modifications are necessary for
providers to deploy HASCHK.

To demonstrate the general applicability of our protocol, we implement a
frontend Google Chrome extension and two different high availability backends:
one based on the public Domain Name System (DNS)~\cite{DNS1, DNS2} via Google
DNS~\cite{GoogleDNS} and another based on the Ring OpenDHT
network~\cite{OpenDHT, savoirfairelinux} via a custom Representational State
Transfer (REST) API. Of course, these HASCHK components of our implementation
should be considered proof-of-concept.

We evaluate the security, performance impact, scalability, and deployment
overhead of our implementation using a publicly available patched HotCRP
instance. While not a panacea, we show that our implementation is capable of
detecting real-world resource compromises, even when the server is under the
attacker's control. Additionally, we find no practical obstacles to efficient
deployment at scale or to security outside of those imposed by the Chrome V2
Extension API.

In summary, our primary contributions are:

First, we propose a practical automated approach to ensuring the integrity of
arbitrary downloads. Our protocol requires no modifications to web
standards/infrastructure or source code, does not employ unreliable heuristics,
does not expect checksums to be co-hosted on the same page as do other automated
approaches, and can be transparently implemented. Further, our protocol can be
used by more than just browsers; HASCHK can protect downloads in FTP clients,
wget/curl clients, and other software.

Second, we present our proof-of-concept implementation, a Google Chrome
extension, and demonstrate our protocol's effectiveness empirically. We show
that our implementation is capable of detecting resource compromises when the
server is under the attacker's control, thus significantly raising the bar for
an attacker. We additionally make our frontend implementation and OpenDHT JSON
API available open source (see \cref{app:availability}).

Third, we evaluate our implementation and find marginal integration and
deployment overhead with no practical obstacles to scalability or security
outside those imposed by the Chrome API. To the best of our knowledge, this is
the first approach that is not susceptible to the pitfalls of co-hosting. Hence,
we conclude that HASCHK is more effective at detecting resource integrity
attacks than manual checksum verification and prior automated schemes.

\subsection{Resource Integrity SCAs}

Modern software requires a complex globally distributed supply chain and
development ecosystem for organizations and other providers to design, develop,
deploy, and maintain products efficiently~\cite{SCA}. Such a globally
distributed ecosystem necessitates integration with potentially many third party
entities, be they specialty driver manufacturers, external content distribution
network (CDN) providers, third party database management software, download
mirrors, etc.

Critically, reliance on third parties, while often cost-effective and
feature-rich, also increases the risk of a security compromise at some point in
the supply chain~\cite{SCA, Stickler}. These types of compromises are known as
Supply Chain Attacks (SCA). In the context of software development, SCAs are the
compromise of an entity's software source code via cyber attack, insider threat,
upstream asset/package management compromise, trusted hardware/vendor
compromise, or some other attack on one or more phases of the software
development life cycle or ``supply chain'' to infect an unsuspecting end
user~\cite{NIST-SCA}.

Every year, major SCAs become more frequent and their fallout more widely
felt~\cite{SCA, NIST-SCA}. Whether major or minor, SCAs are hard to detect, even
harder to prevent, and have the goal of infecting and exploiting victims by
violating the trust between consumer and reputable software vendor.

\begin{table*}[t]
    \centering
    \begin{tabular}{|*{10}{c|}}
      \hline\textbf{Concept}
          & \textbf{Design} & \textbf{Development} & \textbf{Integration} &
          \textbf{Deployment} & \textbf{Maintenance} &
          \textbf{Retirement}\\\hline
      X&X&X&X&\ding{51}&\ding{51}&\ding{51}\\\hline
    \end{tabular}
    \caption{The generic software engineering supply chain.}
     \label{tbl:attacks}
\end{table*}

\tblref{attacks} details the phases of a generic software development supply
chain. For the purposes of this research, we focus exclusively on SCAs targeting
the deployment, maintenance, and retirement phases.

\subsection{Real World Motivations}

Here, we select four relatively recent real-world attacks we believe most
effectively articulate the threat posed by resource integrity SCAs and how
HASCHK might have been used to more effectively mitigate fallout. We examine
each attack, noting the critical points of failure in their checksum-based
resource security models. \\

\noindent\textbf{Case 1: PhpMyAdmin.} For an unspecified amount of time circa
2012, a compromised download mirror in SourceForge's official HTTPS-protected
CDN was distributing a malicious version of the popular database administration
software phpMyAdmin~\cite{SCA-PMA3}. The administrator of the mirror in question
confirmed the attack was due to a vulnerability not shared by SourceForge's
other mirrors~\cite{SCA-PMA2}.

Attackers mutated the software image, injecting files that would allow any
attacker aware of their existence to remotely execute arbitrary PHP code on the
victim's system~\cite{SCA-PMA1}. SourceForge estimates approximately 400 unique
users downloaded this corrupted version of phpMyAdmin before the mirror was
disconnected from their CDN, potentially allowing attackers access to the
private customer data of any number of organizations~\cite{SCA-PMA2}.

While the attackers were able to penetrate a mirror in SourceForge's CDN, the
official phpMyAdmin website was entirely unaffected; the authoritative checksums
listed on the site's download page were similarly unaffected~\cite{SCA-PMA2}.
Hence, a user who was sufficiently motivated, had sufficient technical knowledge
of checksums and how to calculate them, and was also privy to the location of
the correct checksum for the official phpMyAdmin image \emph{might} have noticed
the discrepancy between the two digests. Clearly, a non-trivial number of users
do not meet these criteria. This attack demonstrates the problem of \emph{user
apathy}.\\

\noindent\textbf{Case 2: Linux Mint.} In 2016, the Linux Mint team discovered an
intrusion into their official HTTPS-protected distribution
server~\cite{SCA-MINT1}. Attackers mutated download links originally pointing to
the Linux Mint 17.3 Cinnamon edition ISO, redirecting unsuspecting users to a
separate system hosting a custom Mint ISO compiled with the IRC-based Linux
backdoor malware \emph{Tsunami}~\cite{SCA-MINT2}. The attack affected hundreds
of the downloads during that day, with the attackers claiming that a ``few
hundred'' Linux Mint installs were explicitly under their control. The primary
motivation behind the intrusion was the construction of a
botnet~\cite{SCA-MINT3}. The authoritative checksum displayed on the official
website was also mutated to corroborate the backdoored ISO~\cite{SCA-MINT3},
illustrating the \emph{co-hosting} problem.

Storing the checksum elsewhere may have prevented mutations on the checksum;
still, as demonstrated by the first case, such an effort is not itself a
solution. Hosting a checksum on a secondary system is not very useful if users
downloading the resource protected by that checksum cannot find it or are not
actually \emph{checking} it against a manual calculation. \\

\noindent\textbf{Case 3: Havex.} As part of a widespread espionage campaign
beginning in 2010, Russian Intelligence Services targeted the industrial control
systems of numerous aviation, national defense, critical infrastructure,
pharmaceutical, petrochemical, and other companies and organizations with the
Havex remote access trojan~\cite{SCA-HAVEX1, SCA-HAVEX2}. The attack was carried
out in phases whereby innocuous software images hosted on disparate
\emph{legitimate} vendor websites were targeted for replacement with versions
infected with the Havex malware~\cite{SCA-HAVEX2}. The goal here, as is the case
with all SCAs, was to infect victims indirectly by having the Havex malware
bundled into opaque software dependencies, \eg{ a hardware driver or internal
communication application}.

It is estimated that Havex successfully impacted hundreds or even thousands of
corporations and organizations---mostly in United States and
Europe~\cite{SCA-HAVEX2}. The motivation behind the Havex malware was
intelligence exfiltration and espionage~\cite{SCA-HAVEX1}. How many of these
vendors employed checksums and other mitigations as part of their software
release cycle is not well reported, though investigators note said vendors'
distribution mechanisms were insecure~\cite{SCA-HAVEX2}; however, an automated
resource verification method could have helped mitigate the delivery of
compromised software to users. \\

\noindent\textbf{Case 4: HandBrake.} In May of 2017, users of HandBrake, a
popular open source video transcoder for Mac/OSX, were made aware that they may
have downloaded and installed a trojan riding atop their transcoding software.
Attackers breached an HTTPS-protected HandBrake download mirror, replacing the
legitimate software with a version containing a novel variant of the
\emph{Proton} malware~\cite{SCA-HB1}. The number of users potentially affected
is unreported.

The goal of the attack was the exfiltration of victims' sensitive data,
including decrypted keychains, private keys, browser password databases,
1Password/Lastpass vaults, decrypted files, and victims' personal videos and
other media~\cite{SCA-HB1}. The HandBrake developers recommended users perform
manual checksum verification to determine if their installation media was
compromised~\cite{SCA-HB2}.

Despite the attackers mutating the HandBrake binary, the authoritative checksums
listed on the official HandBrake download page were reportedly left
untouched~\cite{SCA-HB2}. Further, the developers of HandBrake store their
authoritative checksums both on their official website and in their official
GitHub repository~\cite{SCA-HB2}. A sufficiently knowledgeable, sufficiently
motivated user \emph{might} have noticed the discrepancy between their
calculated checksum and the authoritative checksum listed on the download page.

Suppose, however, that the attackers \textit{had} managed to mutate the
checksums on the official website. Then there would be a discrepancy between the
``authoritative'' checksums on the official site and the ``authoritative''
checksums in the GitHub repository---that is \emph{if} users are even aware that
a second set of checksums are available at all. Which are the actual
authoritative checksums? On top of requiring the technical knowledge, a user in
this confusing situation is then expected to ``do the right thing,'' whatever
that happens to be in context.
