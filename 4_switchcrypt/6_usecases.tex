\section{SwitchCrypt Case Studies}\label{sec:usecases}

In this section, we provide four case studies and empirical results
demonstrating the practical utility of cipher switching. We cover a wide range
of situations, highlighting concerns like configuration convergence
(\cref{subsec:uc4}), trading off security and writable space
(\cref{subsec:uc2}), meeting latency goals (\cref{subsec:uc3}), and keeping
within an energy budget (\cref{subsec:uc1}). We also demonstrate the utility of
both temporal and spatial switching strategies, exploring the range of
conditions under which certain strategies are optimal.

\subsection{Balancing Security Goals with a Constrained Energy Budget}\label{subsec:uc1}

This usecase illustrates that, because latency and energy use are correlated
among the ciphers we examined, we can exploit that property using temporal
Forward switching to save our battery. We revisit the motivating example from
\secref{motivation}, demonstrating that the ability to re-cipher individual
nuggets allows us to complete our task while staying within our energy budget.

To simulate a 400MB video download (in parts), we begin sequentially writing 10
40MB files using the Freestyle Balanced cipher configuration. After 5 seconds,
the device enters ``battery saver'' mode. We simulate this event by 1)
underclocking the cores to their lowest frequencies and 2) using
\texttt{taskset} to transition the SwitchCrypt processes to the energy-efficient
LITTLE cores. Afterwards, we complete the remaining workload using the ChaCha8
cipher. We repeat this experiment three times.

\begin{figure}[ht] \textbf{Battery Saver Use Case: Energy-Security Tradeoff vs
   Strict Energy Budget}\par\medskip
   \centering
   {\input{data/usecase-battery.tex}} \caption{Median sequential write total
   energy use with respect to time and security score with respect to time.}
  \label{fig:usecase-battery}
\end{figure}

In \figref{usecase-battery}, we see time versus energy used and average security
score of the backing store. At 0 seconds, we begin writing. At 5 seconds, the
``battery critical'' event occurs, causing the system to be underclocked. At 120
seconds, the system will die. If we blow past our energy ceiling, the system
will die.

Our goal is to finish downloading the file before the device dies. We have three
cipher configuration choices. 1) Favor security and use Freestyle Balanced
exclusively. Our results show that the device will die before completing the
download. 2) Favor low energy use with ChaCha8 exclusively. Our results show
that the device will finish writing early, but we fall below our minimum
security score constraint. Finally, we have 3) favor security and use Freestyle
Balanced except when the system enters a low power state, after which the
storage layer switches to favoring optimal energy use using ChaCha20 via the
Forward switching strategy. Our results show that, while the system uses
slightly more power in the short term, we stay within our energy budget and
finish before the devices dies. Further, when we get our device to a charger,
SwitchCrypt can converge nuggets back to Freestyle Balanced.

On average, using Forward cipher switching resulted in a 3.3x total energy use
reduction, allowing us to remain within our energy budget. We note, however,
that the energy savings is not the point of this experiment. Rather, the lesson
learned is that SwitchCrypt enables the system to move to the right point in the
energy/security tradeoff space that the current task can still be accomplished
before the battery is drained.

\subsection{Variable Security Regions}\label{subsec:uc2}

This usecase illustrates utility of spatial Selective switching to achieve a
performance win over prior work, where the entire drive is encrypted with a
single cipher. We demonstrate \emph{Variable Security Regions} (VSR), where we
can choose to encrypt select files or portions of files with different keys and
ciphers below the filesystem level.

Storing classified materials, corporate secrets, etc. require the highest level
of discretion, yet sensitive information like this can appears within a (much)
larger amount of data that we value less. But if only a small percentage of the
data needs the strongest encryption, then only a small percentage of the data
should have that associated overhead. In this scenario, a user wants to indicate
one or more regions of a file are more sensitive than the others. For example,
perhaps banking transaction information is littered throughout a document;
perhaps passwords and other sensitive information exists within several much
larger files. Using prior techniques, either all the data would be stored with
high overhead, the critical data would be stored without sufficient security, or
the data would have to be split among separate files and managed across
partitioned stores.

We begin by writing 10 5MB and 4KB data (simulating larger and smaller VSR
files) to unique SwitchCrypt instances using ChaCha8 and again on instances
using Freestyle Balanced. We repeat this on a SwitchCrypt setup using Selective
switching with a 3:1 ratio of ChaCha8 nugget I/O operations versus Freestyle
Balanced operations. We repeat this experiment three times.

\begin{figure}[ht] \textbf{VSR Use Case: ChaCha8 vs Freestyle Secure Sequential
4KB, 5MB Performance}\par\medskip
   \centering
   {\input{data/usecase-vsr-bar.tex}} \caption{Median sequential read and
   write performance comparison of 5MB I/O with 3-to-1 ratio of ChaCha8 nuggets
   to Freestyle Secure nuggets, respectively.}
  \label{fig:usecase-vsr-bar}
\end{figure}

In \figref{usecase-vsr-bar}, we see the sequential read and write performance of
4KB and 5MB workloads when nuggets are encrypted exclusively with ChaCha8 or
Freestyle Balanced. Between them, we see Selective switching 3:1 ratio I/O
results.

Our goal is to use VSRs to keep our sensitive data secure while keeping the
performance and battery life benefits of using a fast cipher for the majority of
I/O operations. Using SwitchCrypt Selective switching versus prior work results
in a reduction of 3.1x to 4.8x for read latency and 1.6x to 2.8x for write
latency, all without compromising the security needs of the most sensitive data.

\subsection{Responding to End-of-Life Slowdown in SSDs}\label{subsec:uc3}

This usecase illustrates using temporal Forward switching to offset the
debilitating decline in performance when SSDs reach end-of-life
(EoL)~\cite{SSDEOL1}. We demonstrate the utility of such a system to dynamically
stay within a strict latency budget while meeting minimum security requirements,
which is not possible using prior work.

Due to garbage collection and wear-leveling requirements of SSDs, as free space
becomes constrained, I/O performance drops precipitously~\cite{SSDEOL1}. With
prior work, our strict latency ceiling is violated. However, if SwitchCrypt is
made aware when the backing store is in such a state, we can offset some of the
performance loss by switching the ciphers of high traffic nuggets to the fastest
cipher available using Forward switching.

We begin by writing 10 40MB files to SwitchCrypt per each cipher as a baseline.
We then introduce a delay into SwitchCrypt I/O of $20ms$, simulating drive
slowdown, and repeat the experiment three times.

\begin{figure}[ht] \textbf{SSD EoL Use Case: Latency-Security Tradeoff vs
   Goals}\par\medskip
   {\input{data/usecase-eol-tradeoff.tex}} \caption{Median sequential and
   random 40MB read and write performance comparison: baseline versus simulated
   faulty block device.}
  \label{fig:usecase-eol-tradeoff}
\end{figure}

In \figref{usecase-eol-tradeoff}, we see the sequential and random read and
write performance of a 40MB workload when nuggets are encrypted exclusively with
our choice ciphers. While the latency ceiling and security floor have not
changed, we see increased latency in the delayed workloads.

Our goal is to remain under the latency ceiling while remaining above the
security floor. Thanks to Forward switching, accesses to highly trafficked areas
of the drive can remain performant even during drive end-of-life.

\subsection{Custody Panic: Device Data Under Duress}\label{subsec:uc4}

This usecase illustrates the utility of spatial Mirrored switching to take
advantage of more energy-efficient high-performance ciphers while retaining the
ability to quickly converge the entire backing store to a single high-security
cipher leveraging SSD Instant Secure Erase (ISE).

Nation-state and other adversaries have extensive compute resources, knowledge
of obscure side-channels and back doors (\eg{Dual\_EC\_DRBG~\cite{DualECDRBG}}),
and access to technology like quantum computers. Suppose a scientist were
attempting to re-enter her country through a border entry point when she is
stopped. Further suppose her laptop containing sensitive priceless research data
is confiscated from her custody. Being a security researcher, she has a chance
to trigger a remote wipe, where the laptop uses Instant Secure Erase to reset
its internal storage, permanently destroying all her data. While she certainly
does not want her data falling into the wrong hands, she cannot afford to lose
that data either. In such a scenario, it would be useful if, instead of
destroying the data, the storage layer could switch itself to a more secure
state as quickly as possible.

\begin{figure}[ht] \textbf{Custody Panic Use Case: Security Goals vs Time}\par\medskip
   \centering
   {\input{data/usecase-custody.tex}} \caption{Actual security score vs
   security goal with respect to the time and ISE.}
  \label{fig:usecase-custody}
\end{figure}

In \figref{usecase-eol-tradeoff}, we see the system begins at 0 seconds, where
all data is mirrored across the backing store (perhaps consisting of multiple
physical drives). Both the desired and minimum security score of the drive is
1.5, a balance between performance and security. At 6 seconds, custody panic is
triggered---the desired minimum security score goes to 3, the highest
possible---at which point the system executes ISE and completely erases the
drive containing the minimally scored data. ISE is known to be much faster than
TRIM and completes in as little as 3 seconds~\cite{ISE1,ISE2,ISE3}. Once
complete, the most secure form of the data is all that remains. The backing
store has been ``locked down.''

Our goal is to lock down the backing store, slowing down any attacker as much as
possible such that, even if they copy and permanently store her data off-site
for later attempts at decryption with more advanced compute resources and new
technologies, our researcher's data is some degree more likely to remain
irrecoverable. We show that, given a device that supports SSD ISE, SwitchCrypt,
and the Mirrored strategy, we can quickly and practically converge the backing
store to this locked down state. With prior work, data is either too weakly
encrypted or the device becomes too slow for daily use (latency ceiling). In
exchange, we trade off half of our drive's writeable space.
